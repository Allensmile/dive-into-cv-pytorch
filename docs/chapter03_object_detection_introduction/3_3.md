# 2.3 prior bounding box 先验框

 ### 2.3.1    关于先验框 

​        在二阶段和一阶段目标检测模型中，均有先验框的说法，不同的是在二阶段算法中我们往往称之为anchor（锚点），一阶段算法中我们称之为prior bounding box（先验框），为什么这么区分呢？因为各自的论文就是这么叫的。

​        那么，为什么要有先验框这个概念呢？按理说我们的图片输入模型，模型给出检测结果就好了，为什么还要有先验框？那么关于它的作用，我们不妨回顾一下前面在2.1节所说的那个目标检测最初的解决方案，我们说，我们首先要设置一些框的尺寸，然后遍历图片上每一个坐标得到每一个坐标对应的框，再对这些框进行分类，就可以完成目标检测任务，某种程度上来说，遍历得到的所有框，也是一种先验框，但是问题是什么？问题就是先验框太多了，并且没有针对性，因此这里要解决的问题就是通过遍历图片每一个坐标得到的先验框太多和没有针对性的问题。

​        说完了先验框要解决什么问题，那么它是怎么解决的呢？这里我们简要介绍一下，后面会有详细介绍。

​        首先第一个问题是先验框太多，为什么太多，因为原图太大，如图2-12所示。一个224x224的图片，假设有3个尺寸的先验框，那么就有224x224x3=150528个，但是如果我们不去遍历原图，而是去遍历原图下采样得到的feature map呢？以vgg16的backbone为例，下采样4次，得到7x7的feature map，那就只需要得到7x7x3=147个先验，直接就把数量的问题解决了。

<img src="https://raw.githubusercontent.com/datawhalechina/dive-into-cv-pytorch/master/markdown_imgs/chapter03/2-13.png">

​                                                                                                                      图2-13   先验框数量对比

​        第二个问题就是通过遍历的方法得到的先验框没有针对性，这些先验框中有很多是和图片中我们要检测的目标完全没有交集或者有很小的交集，以iou=0.5为例，与图片中目标的iou<0.5的先验框，这些框我们不经过分类模型判断就能知道它不是目标，那么可以从目标先验框中删去了。注意，我这里说了一个目标先验框，为什么这里没有直接说先验框而是说了目标先验框，那是因为我们的图片中除了要检测的目标，还有一部分就是背景，除目标以外的所有区域都属于背景，对于我们的模型来说，背景也是需要学习的，这样它才能分得清哪些是目标哪些是背景。因此，iou<0.5的先验框就被归到背景先验框队列中去，Iou>=0.5的就可以被归到目标先验框中，一起来供模型学习，如图2-13所示。

<img src="https://raw.githubusercontent.com/datawhalechina/dive-into-cv-pytorch/master/markdown_imgs/chapter03/2-14.png">

​                                                                                                                   图2-14  先验框划分

### 2.3.2 先验框的生成

​        这里，我们来结合代码介绍先验框是如何生成的，更加具体的先验框的使用以及目标先验框和背景先验框的筛选在后面会有详细的介绍。

​        代码路径：[dive-into-cv-pytorch](https://github.com/datawhalechina/dive-into-cv-pytorch/tree/develop)/[code](https://github.com/datawhalechina/dive-into-cv-pytorch/tree/develop/code)/[chapter03_object_detection_introduction](https://github.com/datawhalechina/dive-into-cv-pytorch/tree/develop/code/chapter03_object_detection_introduction)/[a-PyTorch-Tutorial-to-Object-Detection-master](https://github.com/datawhalechina/dive-into-cv-pytorch/tree/develop/code/chapter03_object_detection_introduction/a-PyTorch-Tutorial-to-Object-Detection-master)/**model.py**

```python
"""
	背景介绍：
	1. fmap_dims = 7： VGG16最后的特征图尺寸为 7*7
	2. 在上面的举例中我们是假设了三种尺寸的先验框，然后遍历坐标。在真实的先验框生成过程中，先验框的尺寸是提前设置好的，
	   本教程为特征图上每一个cell定义了共9种不同大小和形状的候选框（3种尺度*3种长宽比=9）
	
	生成过程：
	0. cx， cy表示中心点坐标
	1. 遍历特征图上每一个cell，i+0.5是为了从坐标点移动至cell中心，/fmap_dims目的是将坐标在特征图上归一化
	2. 这个时候我们已经可以在每个cell上各一个框了，但是这个不是我们需要的，我们称之为base_prior_bbox
	3. 根据我们在每个cell上的到的我们称之为base_prior_bbox，结合我们设置的3种尺度obj_scales和3种长宽比aspect_ratios就得到了每个cell的9个先验框。
	4. 最终结果保存在prior_boxes中并返回。
	
	***注意***
	需要注意的是，这个时候我们的到的先验框是针对特征图的尺寸并归一化的，因此要映射到原图计算IOU或者展示，需要：
	img_prior_boxes = prior_boxes * 32 * 7
	其中32是原图到特征图下采样步长，7是特征图尺寸
"""

def create_prior_boxes():
        """
        Create the 441 prior (default) boxes for the network, as described in the tutorial.
        VGG16最后的特征图尺寸为 7*7
        我们为特征图上每一个cell定义了共9种不同大小和形状的候选框（3种尺度*3种长宽比=9）
        因此总的候选框个数 = 7 * 7 * 9 = 441
        :return: prior boxes in center-size coordinates, a tensor of dimensions (441, 4)
        """
        fmap_dims = 7 
        obj_scales = [0.2, 0.4, 0.6]
        aspect_ratios = [1., 2., 0.5]

        prior_boxes = []
        for i in range(fmap_dims):
            for j in range(fmap_dims):
                cx = (j + 0.5) / fmap_dims
                cy = (i + 0.5) / fmap_dims

                for obj_scale in obj_scales:
                    for ratio in aspect_ratios:
                        prior_boxes.append([cx, cy, obj_scale * sqrt(ratio), obj_scale / sqrt(ratio)])

        prior_boxes = torch.FloatTensor(prior_boxes).to(device)  # (441, 4)
        prior_boxes.clamp_(0, 1)  # (441, 4)

        return prior_boxes
```

根据上面的代码，我们得到了先验框，那么接下来进行一下可视化吧，为了便于观看，仅展示特征图中间那个cell对应的先验框。

（可视化代码建议作为练习自己手撸~）

这里为了对比，我们设置两组obj_scales参数。

1. obj_scales = [0.1, 0.2, 0.3]

   <img src="https://raw.githubusercontent.com/datawhalechina/dive-into-cv-pytorch/master/markdown_imgs/chapter03/2-15.png">

   ​                                                                                         图2-15  obj_scales = [0.1, 0.2, 0.3]的先验框可视化

   可以看到，我们在图片中心得到了各个尺度和宽高比的先验框。

   

2. obj_scales = [0.2, 0.4, 0.6]

   <img src="https://raw.githubusercontent.com/datawhalechina/dive-into-cv-pytorch/master/markdown_imgs/chapter03/2-16.png">

   ​                                                                                         图2-16  obj_scales = [0.2, 0.4, 0.6]的先验框可视化

   ​        再来看一下大一些尺度的先验框，可以看到与前一个相比，这个先验框示例存在一个问题，那就是越界，可以看到部分蓝色和绿色的先验框都超出图片界限了，这种情况其实是非常容易出现的，越靠近四周的位置的先验框越容易越界，那么这个问题怎么处理呢？这里我们一般用图片尺寸将越界的先验框进行截断，比如某个先验框左上角坐标是（-5， -9），那么就截断为（0，0），某个先验框右下角坐标是（324，134），当我们的图片大小为（224，224）时，就将其截断为（224，134）。 

 以上就是关于先验框生成的全部内容，先验框是目标检测中一个非常非常重要的概念，关于先验框的知识其实远不止这些，后面会有更加详细的介绍和使用。