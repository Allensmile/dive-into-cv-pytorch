# 3.4 模型结构

## 3.4.1 VGG16作为backbone

<div align=center>
<img src="https://raw.githubusercontent.com/datawhalechina/dive-into-cv-pytorch/master/markdown_imgs/chapter03/2-17.png">
</div>
<center>图3-17 Tiny-Detector的backbone</center>

特征提取层完全采用vgg16的结构作为特征提取模块，去掉fc6和fc7两个全链接层，代码是model.py中的class VGGBase(nn.Module)。由于vgg16的ImageNet预训练模型是使用224x224尺寸训练的，因此我们的网络输入也固定为224x224。网络结构的特征提取层对应代码模块在model.py中的VGGBase，如图3-17。

此目标检测demo的特征提取层是采用VGG16的pool5之前的所有层。目标检测使用的是pool5层输出的7x7的feature map，对这7x7的feature map设置对应的7x7x9个anchor框，其中每一个cell有9个anchor框（见3.3节介绍）具体的图示如图3-18。

|                                                              |                                                              |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| <img src="https://raw.githubusercontent.com/datawhalechina/dive-into-cv-pytorch/master/markdown_imgs/chapter03/2-18_a.jpg"  width="300" height="300"> | <img src="https://raw.githubusercontent.com/datawhalechina/dive-into-cv-pytorch/master/markdown_imgs/chapter03/2-18_b.png" width="300" height="300"> |


<center>图3-18(a)原图，(b)中的9种颜色框代表的是9个anchor框</center>

每个anchor预测由一个边界框和21类别的得分组成（一个背景类）如图3-19，我们选择得分最高的作为边界框对象的类。此目标检测只用最后一层作为目标检测特征层，所以共进行了7x7x9次预测。背景类是最多的，所以很多预测没有包含任何对象，我们的定义和SSD一致，把这个背景类作为“0”，来表示它没有任何对象是背景。包含边界框和分类框的多重预测称为multibox预测。

<div align=center>
<img src="https://raw.githubusercontent.com/datawhalechina/dive-into-cv-pytorch/master/markdown_imgs/chapter03/2-19.png">
</div>
<center>图3-19 Tiny-Detector的输出示例</center>

此目标检测的分类头预测和回归头预测是怎么得到的？

在pool5层后得到的是7x7的feature map，然后在此feature map上采用3x3卷积过滤器计算位置和类别分数。这些3x3的卷积滤波器就像常规的CNN过滤器一样，每个过滤器输出25个通道：每类21个分数加上一个边界框，如图3-20。

<div align=center>
<img src="https://raw.githubusercontent.com/datawhalechina/dive-into-cv-pytorch/master/markdown_imgs/chapter03/2-20.png">
</div>
<center>图3-20 Tiny-Detector对于一个anchor框的输出示例</center>

此处的计算在pool5层上采用3x3的filters，输入是512通道，输出是25通道。

​                                         (9x3x3x512x(24+4))

​                   (7x7x512)------------------------------------>(7x7x9x(21+4))

## 3.4.2 分类头和回归头

### 3.4.2.1 边界框的编解码

对于此目标检测的最终的目标框是通过回归偏移anchor（prior box）框得到的。这就意味着我们要使用每个先验框作为近似的起点，然后找出需要调整多少来获得更准确的边界框预测。 如果每个预测的边界框与先验框有一点偏差的话，那么我们的目标就是需要找一种方法来量化计算这个偏差。对于一只狗的预测边界框和先验的边界框如下图3-21所示：

<div align=center>
<img src="https://raw.githubusercontent.com/datawhalechina/dive-into-cv-pytorch/master/markdown_imgs/chapter03/2-21.png">
</div>
<center>图3-21 默认框和预测框示例</center>

​                                               $$g_{cx}=\frac{c_x-\hat{c}_x}{\hat{w}}$$

​                                               $$g_{cy}=\frac{c_y-\hat{c}_y}{\hat{h}}$$

​                                               $$g_w=log(\frac{w}{\hat{w}})$$

​                                               $$g_h=log(\frac{h}{\hat{h}})$$

一个边界框的定位和大小能够通过prior box的offsets ($g_{cx},g_{cy},g_x,g_h$)得到，这个就是编码过程。考虑到每一个先验都是经过调整以获得更精确的预测，这四个偏移量($g_{cx},g_{cy},g_x,g_h$) 就是我们将边界框坐标的返回形式。

### 3.4.2.2 分类头与回归头预测

对于输出7x7的feature map上的每个先验框我们想预测：

1）边界框的一组21类分数，其中包括VOC的20类和一个背景类。

2）边界框的偏移量($g_{cx},g_{cy},g_w,g_h$)。

为了得到我们想预测的类别和偏移量，我们需要为每个feature map提供两个卷基层：

1）一个分类预测的卷积层采用3x3卷积核padding和stride都为1，使用21个滤波器对每个位置上的先验进行评估。

2）一个定位预测卷基层，每个位置使用3x3卷积核padding和stride都为1，使用4个这样的滤波器对每个位置上的先验进行评估。

我们直观的看看这些卷积上的输出，见下图3-22：

<div align=center>
<img src="https://raw.githubusercontent.com/datawhalechina/dive-into-cv-pytorch/master/markdown_imgs/chapter03/2-22.png">
</div>
<center>图 3-22 Tiny-Detector输出示例</center> 

这个定位层和分类预测层的输出分别用蓝色和黄色表示。其feature map的大小7x7保持不变。我们真正关心的是第三维度通道数，这个包含实际的预测。把其具体的展开可以看到如下图3-23所示：

<div align=center>
<img src="https://raw.githubusercontent.com/datawhalechina/dive-into-cv-pytorch/master/markdown_imgs/chapter03/2-23.png">
</div>
<center>图3-23 每个cell中9个anchor预测编码偏移量</center>

可以看到，在定位预测的每个位置上的通道值，代表了相对于该位置的先验的编码偏移量。做相同的操作，其类别21类：

<div align=center>
<img src="https://raw.githubusercontent.com/datawhalechina/dive-into-cv-pytorch/master/markdown_imgs/chapter03/2-24.png">
</div>
<center>图3-24 每个cell中9个anchor预测分类得分</center>

与位置偏移类似，这些通道表示先验框的类别得分。通过计算，我们的模型定义了总共441个先验框，因此，将有441个编码偏移形式的预测和441组分类分数，如图3-25所示。

<div align=center>
<img src="https://raw.githubusercontent.com/datawhalechina/dive-into-cv-pytorch/master/markdown_imgs/chapter03/2-25.png">
</div>
<center>图3-25 pool5层输出分类和回归结果</center>

